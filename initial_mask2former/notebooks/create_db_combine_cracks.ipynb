{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db54683c-bf87-499a-96c2-a05dd81979f6",
   "metadata": {},
   "source": [
    "### Create db where all mask except crack related are set to background (removed) and all crack classes are combined into one#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93c6c9-77eb-46e8-bfc3-8c2927fd6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_DIR = '/app/data'\n",
    "SOURCE_IMG_DIR = f'{BASE_DIR}/2026-01-19-defect_dataset/images'\n",
    "SOURCE_LBL_DIR = f'{BASE_DIR}/2026-01-19-defect_dataset/labels_full'\n",
    "\n",
    "# Output directory changes based on your choice\n",
    "OUT_BASE_MERGED = f'{BASE_DIR}/2026-01-19-defect_dataset/labels_cracks_merged'\n",
    "OUT_BASE_MULTICLASS = f'{BASE_DIR}/2026-01-19-defect_dataset/labels_basic_defects'\n",
    "\n",
    "TARGET_CLASS_IDS = [1, 2, 3, 4, 5, 6, 7, 13]\n",
    "\n",
    "def combine_and_filter_dataset(merge=True):\n",
    "    # Select path based on mode\n",
    "    out_base = OUT_BASE_MERGED if merge else OUT_BASE_MULTICLASS\n",
    "\n",
    "    if os.path.exists(out_base):\n",
    "        print(f\"Note: Output folder {out_base} already exists.\")\n",
    "    \n",
    "    os.makedirs(out_base, exist_ok=True)\n",
    "\n",
    "    label_files = [f for f in os.listdir(SOURCE_LBL_DIR) if f.endswith('.png')]\n",
    "    processed_count = 0\n",
    "    empty_count = 0\n",
    "\n",
    "    print(f\"üöÄ Mode: {'MERGE (Binary)' if merge else 'PRESERVE (Multiclass)'}\")\n",
    "    print(f\"Processing {len(label_files)} files...\")\n",
    "\n",
    "    for lbl_file in label_files:\n",
    "        src_lbl_path = os.path.join(SOURCE_LBL_DIR, lbl_file)\n",
    "        mask = np.array(Image.open(src_lbl_path).convert('L'))\n",
    "        \n",
    "        # New Dynamic Logic\n",
    "        if merge:\n",
    "            # Flatten everything in TARGET_CLASS_IDS to 1\n",
    "            new_mask = np.zeros_like(mask)\n",
    "            new_mask[np.isin(mask, TARGET_CLASS_IDS)] = 1\n",
    "        else:\n",
    "            # Keep original IDs (1, 2, 3) for targets, everything else 0\n",
    "            new_mask = np.where(np.isin(mask, TARGET_CLASS_IDS), mask, 0)\n",
    "        \n",
    "        # Skip if no target pixels exist in the final mask\n",
    "        if not np.any(new_mask > 0):\n",
    "            empty_count += 1\n",
    "\n",
    "        # Save Label\n",
    "        result_img = Image.fromarray(new_mask.astype(np.uint8))\n",
    "        result_img.save(os.path.join(out_base, lbl_file))\n",
    "        processed_count += 1\n",
    "\n",
    "    print(f\"‚úÖ Saved: {processed_count} images | ‚ùå Empty: {empty_count}\")\n",
    "    print(f\"üìÇ Location: {out_base}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Change to False to fix your spatial confusion/233px error!\n",
    "    combine_and_filter_dataset(merge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536d3d4a-1fce-4dba-96a8-592aaffd7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Verifying output classes...\n",
      "------------------------------\n",
      "Found unique class IDs across all files: [0, 1]\n",
      "‚úÖ SUCCESS: Dataset contains strictly 2 classes (0: Background, 1: Crack).\n"
     ]
    }
   ],
   "source": [
    "def verify_output():\n",
    "    print(\"\\nüîé Verifying output classes...\")\n",
    "    label_files = os.listdir(OUT_LBL_DIR)\n",
    "    global_unique_ids = set()\n",
    "    errors = []\n",
    "\n",
    "    for f in label_files:\n",
    "        path = os.path.join(OUT_LBL_DIR, f)\n",
    "        # Load the newly created mask\n",
    "        mask = np.array(Image.open(path).convert('L'))\n",
    "        unique = np.unique(mask)\n",
    "        \n",
    "        # Update global list of IDs found\n",
    "        for u in unique:\n",
    "            global_unique_ids.add(u)\n",
    "        \n",
    "        # Check for any value that is NOT 0 or 1\n",
    "        if not np.all(np.isin(unique, [0, 1])):\n",
    "            errors.append(f)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Found unique class IDs across all files: {sorted(list(global_unique_ids))}\")\n",
    "    \n",
    "    if len(errors) == 0 and global_unique_ids.issubset({0, 1}):\n",
    "        print(\"‚úÖ SUCCESS: Dataset contains strictly 2 classes (0: Background, 1: Crack).\")\n",
    "    else:\n",
    "        print(f\"‚ùå FAILURE: Found unexpected classes or files with errors: {errors}\")\n",
    "\n",
    "verify_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e6cd5d1-01de-4f2c-9342-b23fe250b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6081 images in folder. Creating random split...\n",
      "‚úÖ Random split files created in /app/data/multi_crack/splits\n",
      "Stats: 1500 train images, 100 val images.\n"
     ]
    }
   ],
   "source": [
    "# Create divisio train and test\n",
    "\n",
    "import os\n",
    "import random\n",
    "# CONFIGURATION\n",
    "# Make sure this matches your folder name\n",
    "DATA_DIR = '/app/data/multi_crack'\n",
    "IMG_DIR = os.path.join(DATA_DIR, 'images')\n",
    "SPLITS_DIR = os.path.join(DATA_DIR, 'splits')\n",
    "\n",
    "def create_train_val_split_from_folder():\n",
    "    # 1. Setup paths\n",
    "    os.makedirs(SPLITS_DIR, exist_ok=True)\n",
    "\n",
    "    # 2. Scan folder for all images\n",
    "    # We look for .jpg and .png to be safe\n",
    "    all_images = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    if not all_images:\n",
    "        print(f\"‚ùå Error: No images found in {IMG_DIR}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_images)} images in folder. Creating random split...\")\n",
    "\n",
    "    # 3. Random Shuffle\n",
    "    random.shuffle(all_images) \n",
    "\n",
    "    val_files = all_images[:100]\n",
    "    remaining_images = all_images[100:]\n",
    "    train_files = remaining_images[:1500]\n",
    "\n",
    "    # 6. Strip extensions (remove .jpg/.png) for the text files\n",
    "    # This is crucial for segmentation dataloaders that expect just the ID\n",
    "    train_names = [os.path.splitext(f)[0] for f in train_files]\n",
    "    val_names = [os.path.splitext(f)[0] for f in val_files]\n",
    "\n",
    "    # 7. Write to files\n",
    "    with open(os.path.join(SPLITS_DIR, 'train.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(train_names))\n",
    "\n",
    "    with open(os.path.join(SPLITS_DIR, 'val.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(val_names))\n",
    "\n",
    "    print(f\"‚úÖ Random split files created in {SPLITS_DIR}\")\n",
    "    print(f\"Stats: {len(train_names)} train images, {len(val_names)} val images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_train_val_split_from_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
