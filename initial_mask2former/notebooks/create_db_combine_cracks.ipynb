{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db54683c-bf87-499a-96c2-a05dd81979f6",
   "metadata": {},
   "source": [
    "### Create db where all mask except crack related are set to background (removed) and all crack classes are combined into one#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb93c6c9-77eb-46e8-bfc3-8c2927fd6462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Output folder /app/data/combine_crack already exists.\n",
      "Starting processing of 7286 files...\n",
      "Target merging classes: [1, 2, 3]\n",
      "--- Processing Complete ---\n",
      "‚úÖ Saved: 6081 images (containing merged cracks)\n",
      "‚ùå Skipped: 1205 images (background only / no cracks)\n",
      "üìÇ Output location: /app/data/combine_crack\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_DIR = '/app/data'\n",
    "SOURCE_IMG_DIR = f'{BASE_DIR}/2026-01-19-defect_dataset/images'\n",
    "SOURCE_LBL_DIR = f'{BASE_DIR}/2026-01-19-defect_dataset/labels'\n",
    "\n",
    "# New output directories\n",
    "OUT_BASE = f'{BASE_DIR}/combine_crack'\n",
    "OUT_IMG_DIR = f'{OUT_BASE}/images'\n",
    "OUT_LBL_DIR = f'{OUT_BASE}/labels'\n",
    "\n",
    "# ‚ö†Ô∏è UPDATE THESE IDS: Enter the integer values for your crack classes\n",
    "# Example: If cracks=1, alligator=2, severe=3, put [1, 2, 3]\n",
    "TARGET_CLASS_IDS = [1, 2, 3] \n",
    "\n",
    "def combine_and_filter_dataset():\n",
    "    # 1. Setup output directories\n",
    "    if os.path.exists(OUT_BASE):\n",
    "        print(f\"Warning: Output folder {OUT_BASE} already exists.\")\n",
    "    os.makedirs(OUT_IMG_DIR, exist_ok=True)\n",
    "    os.makedirs(OUT_LBL_DIR, exist_ok=True)\n",
    "\n",
    "    # Get list of label files\n",
    "    label_files = [f for f in os.listdir(SOURCE_LBL_DIR) if f.endswith('.png')]\n",
    "    \n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    print(f\"Starting processing of {len(label_files)} files...\")\n",
    "    print(f\"Target merging classes: {TARGET_CLASS_IDS}\")\n",
    "\n",
    "    for lbl_file in label_files:\n",
    "        # Construct paths\n",
    "        src_lbl_path = os.path.join(SOURCE_LBL_DIR, lbl_file)\n",
    "        \n",
    "        # 2. Load and Process Mask\n",
    "        # Load as grayscale (L) to get integer class IDs\n",
    "        mask = np.array(Image.open(src_lbl_path).convert('L'))\n",
    "        \n",
    "        # Create a new blank mask (all zeros/background)\n",
    "        new_mask = np.zeros_like(mask)\n",
    "        \n",
    "        # 3. Merge Logic\n",
    "        # Where the original mask contains ANY of the target classes, set new mask to 1\n",
    "        mask_matches_target = np.isin(mask, TARGET_CLASS_IDS)\n",
    "        new_mask[mask_matches_target] = 1\n",
    "        \n",
    "        # 4. Filter Logic (Skip if empty)\n",
    "        # If the new mask has no cracks (value 1), we skip copying this file\n",
    "        if not np.any(new_mask == 1):\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # 5. Save New Mask\n",
    "        # Save as standard palette or grayscale png\n",
    "        result_img = Image.fromarray(new_mask.astype(np.uint8))\n",
    "        result_img.save(os.path.join(OUT_LBL_DIR, lbl_file))\n",
    "\n",
    "        # 6. Copy Corresponding Image\n",
    "        # We assume image has same basename but likely .jpg extension\n",
    "        # (Handling both .jpg and .png for safety based on your previous code)\n",
    "        img_name_jpg = lbl_file.replace('.png', '.jpg')\n",
    "        img_name_png = lbl_file\n",
    "        \n",
    "        src_img_path = None\n",
    "        dst_img_name = None\n",
    "\n",
    "        if os.path.exists(os.path.join(SOURCE_IMG_DIR, img_name_jpg)):\n",
    "            src_img_path = os.path.join(SOURCE_IMG_DIR, img_name_jpg)\n",
    "            dst_img_name = img_name_jpg\n",
    "        elif os.path.exists(os.path.join(SOURCE_IMG_DIR, img_name_png)):\n",
    "            src_img_path = os.path.join(SOURCE_IMG_DIR, img_name_png)\n",
    "            dst_img_name = img_name_png\n",
    "        \n",
    "        if src_img_path:\n",
    "            shutil.copy(src_img_path, os.path.join(OUT_IMG_DIR, dst_img_name))\n",
    "            processed_count += 1\n",
    "        else:\n",
    "            print(f\"Warning: Label {lbl_file} has no matching image file. Skipped.\")\n",
    "\n",
    "    print(\"--- Processing Complete ---\")\n",
    "    print(f\"‚úÖ Saved: {processed_count} images (containing merged cracks)\")\n",
    "    print(f\"‚ùå Skipped: {skipped_count} images (background only / no cracks)\")\n",
    "    print(f\"üìÇ Output location: {OUT_BASE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combine_and_filter_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536d3d4a-1fce-4dba-96a8-592aaffd7c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Verifying output classes...\n",
      "------------------------------\n",
      "Found unique class IDs across all files: [0, 1]\n",
      "‚úÖ SUCCESS: Dataset contains strictly 2 classes (0: Background, 1: Crack).\n"
     ]
    }
   ],
   "source": [
    "def verify_output():\n",
    "    print(\"\\nüîé Verifying output classes...\")\n",
    "    label_files = os.listdir(OUT_LBL_DIR)\n",
    "    global_unique_ids = set()\n",
    "    errors = []\n",
    "\n",
    "    for f in label_files:\n",
    "        path = os.path.join(OUT_LBL_DIR, f)\n",
    "        # Load the newly created mask\n",
    "        mask = np.array(Image.open(path).convert('L'))\n",
    "        unique = np.unique(mask)\n",
    "        \n",
    "        # Update global list of IDs found\n",
    "        for u in unique:\n",
    "            global_unique_ids.add(u)\n",
    "        \n",
    "        # Check for any value that is NOT 0 or 1\n",
    "        if not np.all(np.isin(unique, [0, 1])):\n",
    "            errors.append(f)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Found unique class IDs across all files: {sorted(list(global_unique_ids))}\")\n",
    "    \n",
    "    if len(errors) == 0 and global_unique_ids.issubset({0, 1}):\n",
    "        print(\"‚úÖ SUCCESS: Dataset contains strictly 2 classes (0: Background, 1: Crack).\")\n",
    "    else:\n",
    "        print(f\"‚ùå FAILURE: Found unexpected classes or files with errors: {errors}\")\n",
    "\n",
    "verify_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6cd5d1-01de-4f2c-9342-b23fe250b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6081 images in folder. Creating random split...\n",
      "‚úÖ Random split files created in /app/data/combine_crack/splits\n",
      "Stats: 1500 train images, 100 val images.\n"
     ]
    }
   ],
   "source": [
    "# Create divisio train and test\n",
    "\n",
    "import os\n",
    "import random\n",
    "# CONFIGURATION\n",
    "# Make sure this matches your folder name\n",
    "DATA_DIR = '/app/data/combine_crack'\n",
    "IMG_DIR = os.path.join(DATA_DIR, 'images')\n",
    "SPLITS_DIR = os.path.join(DATA_DIR, 'splits')\n",
    "\n",
    "def create_train_val_split_from_folder():\n",
    "    # 1. Setup paths\n",
    "    os.makedirs(SPLITS_DIR, exist_ok=True)\n",
    "\n",
    "    # 2. Scan folder for all images\n",
    "    # We look for .jpg and .png to be safe\n",
    "    all_images = [f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    if not all_images:\n",
    "        print(f\"‚ùå Error: No images found in {IMG_DIR}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(all_images)} images in folder. Creating random split...\")\n",
    "\n",
    "    # 3. Random Shuffle\n",
    "    random.shuffle(all_images) \n",
    "\n",
    "    val_files = all_images[:100]\n",
    "    remaining_images = all_images[100:]\n",
    "    train_files = remaining_images[:1500]\n",
    "\n",
    "    # 6. Strip extensions (remove .jpg/.png) for the text files\n",
    "    # This is crucial for segmentation dataloaders that expect just the ID\n",
    "    train_names = [os.path.splitext(f)[0] for f in train_files]\n",
    "    val_names = [os.path.splitext(f)[0] for f in val_files]\n",
    "\n",
    "    # 7. Write to files\n",
    "    with open(os.path.join(SPLITS_DIR, 'train.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(train_names))\n",
    "\n",
    "    with open(os.path.join(SPLITS_DIR, 'val.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(val_names))\n",
    "\n",
    "    print(f\"‚úÖ Random split files created in {SPLITS_DIR}\")\n",
    "    print(f\"Stats: {len(train_names)} train images, {len(val_names)} val images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_train_val_split_from_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
